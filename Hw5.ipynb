{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88bb1cd-3063-45a9-8a93-d661959333f6",
   "metadata": {},
   "source": [
    "CISC 7700X HW# 5: Using data from: spambase, build a Naive Bayes email classifier. Nothing too fancy, just a training module, and a classifier module. Submit code and accuracy you get on the spambase dataset. [hint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf08e0e-8d80-4dc3-9d3c-f3ede0b76491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests) (2024.2.2)\n",
      "Extracted contents to /home/studio-lab-user/sagemaker-studiolab-notebooks/Cisc7700/Cisc7700_hw5\n"
     ]
    }
   ],
   "source": [
    "#http://theparticle.com/cs/bc/dsci/20211107bayes.tar.gz\n",
    "!pip install requests\n",
    "\n",
    "import requests\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "def extract_tar_file(url, extract_path):\n",
    "    # Step 1: Stream download the file\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "    # Create a BytesIO buffer to hold the tar.gz data\n",
    "    tar_buffer = io.BytesIO()\n",
    "\n",
    "    # Write the streamed content to the buffer\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            tar_buffer.write(chunk)\n",
    "\n",
    "    # Move the buffer's cursor to the beginning\n",
    "    tar_buffer.seek(0)\n",
    "\n",
    "    # Step 2: Extract the tar.gz file from the buffer\n",
    "    with tarfile.open(fileobj=tar_buffer, mode='r:gz') as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "        print(f\"Extracted contents to {extract_path}\")\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"http://theparticle.com/cs/bc/dsci/20211107bayes.tar.gz\"  # Replace with your URL\n",
    "    extract_path = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/Cisc7700/Cisc7700_hw5\" # Directory to extract the contents !pwd\n",
    "\n",
    "    extract_tar_file(url, extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4bf0d3-c556-48e3-90d6-aac645bd8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "# Initialize global dictionaries and counters\n",
    "catcnttot = 0  # Total number of categories (documents)\n",
    "catcnt = {}    # Count of each category\n",
    "model = {}     # Word counts per category\n",
    "modeltot = {}  # Total word counts per category\n",
    "\n",
    "def train(cats):\n",
    "    global catcnttot\n",
    "    \n",
    "    for cat in cats:\n",
    "        for filename in os.listdir(cat):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(cat, filename)\n",
    "    \n",
    "                if cat in catcnt:\n",
    "                    catcnt[cat] += 1\n",
    "                else:\n",
    "                    catcnt[cat] = 1\n",
    "\n",
    "                catcnttot += 1\n",
    "\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                    content = infile.read()\n",
    "                    words = content.lower().split()\n",
    "\n",
    "                    for word in words:\n",
    "                        if cat not in model:\n",
    "                            model[cat] = {}\n",
    "                        \n",
    "                        if word in model[cat]:\n",
    "                            model[cat][word] += 1\n",
    "                        else:\n",
    "                            model[cat][word] = 1\n",
    "\n",
    "                        if cat in modeltot:\n",
    "                            modeltot[cat] += 1\n",
    "                        else:\n",
    "                            modeltot[cat] = 1\n",
    "    \n",
    "    for filename in os.listdir(\"test\"):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(\"test\", filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                content = infile.read()\n",
    "                words = content.lower().split()\n",
    "            result = {}\n",
    "            for cat in cats:\n",
    "                if cat in catcnt:\n",
    "                    result[cat] = math.log(catcnt[cat] / catcnttot)\n",
    "                else:\n",
    "                    result[cat] = math.log(1 / catcnttot)\n",
    "\n",
    "                for word in words:\n",
    "                    if cat in model and word in model[cat]:\n",
    "                        result[cat] += math.log(model[cat][word] / modeltot[cat])\n",
    "                    else:\n",
    "                        result[cat] += math.log(0.001)\n",
    "\n",
    "            for cat in result:\n",
    "                result[cat] = math.exp(result[cat])\n",
    "\n",
    "            total = 0\n",
    "            for it in result.values():\n",
    "                total += it\n",
    "            for cat in result:\n",
    "                result[cat] = result[cat] / total\n",
    "\n",
    "            print(f\"{filename}: spam={result['spam']}; ham={result['ham']}\")\n",
    "\n",
    "folder=[\"spam\", \"ham\"]\n",
    "train(folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
